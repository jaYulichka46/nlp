# Dataset Card: Ukrainian News Classification

## Назва проєкту
Класифікація українських новин за тематичними категоріями.

## Задача
Задача А: Класифікація текстів.
- **Input:** Заголовок та основний текст новини.
- **Output:** Одна з 5 категорій (політика, спорт, новини, бізнес, технології).

## Джерело даних
Бібліотека `ua-datasets`, корпус новин ресурсу 24tv.ua.

## Обсяг
- **Текстів:** 120,417
- **Класів:** 5
- **Медіанна довжина:** 126 слів (896 символів) на текст.

## Мова та домени
Українська мова. Домени: Політика (40.3к), Спорт (28.4к), Новини (25.2к), Бізнес (14.7к), Технології (11.6к).

## Очищення та Нормалізація (Оновлено за результатами Lab 2)
Для підготовки даних реалізовано детермінований пайплайн препроцесингу (`src/preprocess.py`), який включає:
1. **Виправлення кодування:** Автоматичне відновлення пошкоджених символів (mojibake) за допомогою бібліотеки `ftfy`.
2. **Нормалізація типографіки:** Уніфікація лапок-ялинок («» → "), стандартизація апострофів, заміна табличних артефактів (вертикальні рисочки `|`) та схлопування подвійних CSV-лапок.
3. **Маскування PII та посилань:** Усі прямі лінки та електронні адреси замінено на безпечні токени `<URL>`, `<EMAIL>`.
4. **Очищення від медіа-шуму:** Видалено специфічні заклики соцмереж (наприклад, технічний шум Instagram).
5. **Розумне розбиття на речення:** Створено кастомний sentence_splitter, який коректно обробляє українські географічні скорочення (м., вул.), ініціали та абревіатури (наприклад, Еспресо.TV), не розриваючи речення на хибних крапках.

## Ризики та якість даних
### Зняті ризики (Lab 2):
- **Технічний шум та артефакти:** Успішно усунуто проблеми з кодуванням та артефактами парсингу таблиць/соцмереж. Дані готові до токенізації.
- **Помилки сегментації:** Ризик неправильного розбиття на речення через скорочення мінімізовано завдяки регулярним виразам із захистом (lookahead/lookbehind).

### Залишкові ризики:
- **Дисбаланс класів:** Клас "політика" залишається домінуючим (~33% датасету). Це потребуватиме використання зважених функцій втрат (class weights) або методів семплінгу на етапі навчання моделі.
- **Дублікати та аномалії:** Наявність 703 точних дублікатів та дуже коротких текстів (менше 5 слів). Потребує фільтрації перед подачею в модель.

## План наступного кроку (Lab 3)
1. Фільтрація залишкових дублікатів та аномально коротких текстів.
2. Проведення лематизації (зведення слів до початкової форми).
3. Векторизація тексту (TF-IDF або використання word embeddings) та побудова baseline-моделі класифікації з урахуванням класового дисбалансу.